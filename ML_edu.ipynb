{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "ML_Edu",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/hinkim/Machine_Learning/blob/master/ML_edu.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "whvLswUeQqsY",
        "colab_type": "text"
      },
      "source": [
        "## Check installation and version"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qTo5LVJ0PQim",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "24593f0c-e18f-43fb-8641-069c34676fe9"
      },
      "source": [
        "import tensorflow as tf\n",
        "tf.__version__"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'1.15.0'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 1
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "InAOMIqFQwZw",
        "colab_type": "text"
      },
      "source": [
        "## TensorFlow Hello World!"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a6nH8gvMQcdY",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "3ed5366b-46fd-4ed6-cb82-1ceecb2a2c71"
      },
      "source": [
        "# Create a constant op\n",
        "# This op is added as a node to the default graph\n",
        "# node 생성\n",
        "hello = tf.constant(\"Hello, TensorFlow!\")\n",
        "\n",
        "# session 생성\n",
        "# start a TF session\n",
        "sess = tf.Session()\n",
        "\n",
        "# session에서 hello node 실행\n",
        "# run the op and get result\n",
        "print(sess.run(hello))"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "b'Hello, TensorFlow!'\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9pBfaK2URnAt",
        "colab_type": "text"
      },
      "source": [
        "## Computational Graph\n",
        "\n",
        "\n",
        "<img width=\"509\" alt=\"Tensorflow\" src=\"https://user-images.githubusercontent.com/51468250/67445021-34790200-f646-11e9-9ef7-2f147cc5373c.PNG\">\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HdsZoGPzRpqZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# 1. Build graph using TensorFlow operations\n",
        "node1 = tf.constant(3.0, tf.float32)\n",
        "node2 = tf.constant(4.0)\n",
        "node3 = tf.add(node1, node2)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aN8gtqZxR1YO",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 74
        },
        "outputId": "575d5afe-e10d-4b3f-fd50-f34f986930f6"
      },
      "source": [
        "# 2. feed data and run graph (operation)\n",
        "print(\"node1: \", node1, \"node2: \", node2)\n",
        "print(\"node3: \", node3)"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "node1:  Tensor(\"Const_1:0\", shape=(), dtype=float32) node2:  Tensor(\"Const_2:0\", shape=(), dtype=float32)\n",
            "node3:  Tensor(\"Add:0\", shape=(), dtype=float32)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FsPPQe7FR-P_",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "outputId": "099e28f0-866a-4bdc-8652-fb89b2440fe8"
      },
      "source": [
        "# update varables in the graph (and return values)\n",
        "sess = tf.Session()\n",
        "print(\"sess.run(node1, node2): \", sess.run([node1, node2]))\n",
        "print(\"sess.run(node3): \", sess.run(node3))"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "sess.run(node1, node2):  [3.0, 4.0]\n",
            "sess.run(node3):  7.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oeWL5pb4VmFI",
        "colab_type": "text"
      },
      "source": [
        "## Placeholder\n",
        "\n",
        "실행시킬 때 값을 넘겨주는 형식"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b4uKJd3DVn42",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "outputId": "53dcc4ef-4e2d-4034-f639-9342832c94d3"
      },
      "source": [
        "a = tf.placeholder(tf.float32)\n",
        "b = tf.placeholder(tf.float32)\n",
        "adder_node = a + b # + provides a shortcut for tf.add(a,b)\n",
        "\n",
        "print(sess.run(adder_node, feed_dict={a: 3, b: 4.5}))\n",
        "print(sess.run(adder_node, feed_dict={a: [1,3], b: [2,4]}))"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "7.5\n",
            "[3. 7.]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "es2riYgVXuYq",
        "colab_type": "text"
      },
      "source": [
        "## Tensor Ranks, Shapes\n",
        "\n",
        "Ranks: 몇 차원의 array인가? \n",
        "\n",
        "<img width=\"452\" alt=\"Rank\" src=\"https://user-images.githubusercontent.com/51468250/67445803-2b3d6480-f649-11e9-91ab-9db8fae56ae4.PNG\">\n",
        "\n",
        "Shapes: 각각의 element에 몇 개씩 들어있는가?\n",
        "\n",
        "<img width=\"464\" alt=\"Shape\" src=\"https://user-images.githubusercontent.com/51468250/67445805-2b3d6480-f649-11e9-8d0d-28d9dfff37a6.PNG\">\n",
        "\n",
        "\n",
        "ex)\n",
        "\n",
        "t = [[1, 2, 3], [4, 5, 6], [7, 8, 9]]\n",
        "=> [3, 3]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iddpo47HYlfC",
        "colab_type": "text"
      },
      "source": [
        "## Linear Regression\n",
        "### Linear하게 가설을 세운다는 것: 어떤 데이터가 있을 때 여기에 잘 맞는 linear한 선을 찾는 것, 어떤 것이 더 데이터에 잘 맞는 선일까, 이 선을 찾는 것이 학습을 하는 것\n",
        "\n",
        "H(x) = Wx + b\n",
        "\n",
        "\n",
        "## 어떤 가설이 좋은 것인가?\n",
        "### 실제 데이터와 가설이 나타내는 점과의 거리를 비교해서 거리가 짧은 것 => Cost function\n",
        "\n",
        "## Cost function (Loss function)\n",
        "### How fit the line to our (training) data\n",
        "\n",
        "## 학습\n",
        "### w, b를 조정해서 coss function을 minimize, 가장 작은 값이 되게 하는 것\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mrAAPuRbZ819",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# 1. Build graph using TF operations\n",
        "\n",
        "# X and Y data\n",
        "x_train = [1, 2, 3]\n",
        "y_train = [1, 2, 3]\n",
        "\n",
        "# Try to find values for W and b to compute y_data = x_data * W + b\n",
        "# We know that W should be 1 and b should be 0\n",
        "# But let TensorFlow figure it out\n",
        "# Variable: 학습하는 과정에서 Tensorflow가 변경시키는 값\n",
        "# 처음에 w, b값을 랜덤하게 1차원 array로 줌\n",
        "W = tf.Variable(tf.random_normal([1]), name=\"weight\")\n",
        "b = tf.Variable(tf.random_normal([1]), name=\"bias\")\n",
        "\n",
        "# Our hypothesis XW+b\n",
        "hypothesis = x_train * W + b"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z-uDWY-TiyBe",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# cost/loss function\n",
        "cost = tf.reduce_mean(tf.square(hypothesis - y_train))\n",
        "\n",
        "\n",
        "# optimizer\n",
        "optimizer = tf.train.GradientDescentOptimizer(learning_rate=0.01)\n",
        "train = optimizer.minimize(cost)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AsYgyA7LjmHN",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 399
        },
        "outputId": "37551feb-528a-4bb3-f703-b7b544621f7a"
      },
      "source": [
        "# Launch the graph in a session.\n",
        "sess = tf.Session()\n",
        "\n",
        "# Initializes global variables in the graph.\n",
        "sess.run(tf.global_variables_initializer())\n",
        "\n",
        "# Fit the line\n",
        "for step in range(2001):\n",
        "  sess.run(train)\n",
        "  if step % 100 == 0:\n",
        "    print(step, sess.run(cost), sess.run(W), sess.run(b))"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0 0.32028162 [1.0030866] [-0.5721018]\n",
            "100 0.020465186 [1.1661496] [-0.3777018]\n",
            "200 0.012646268 [1.1306101] [-0.2969076]\n",
            "300 0.007814606 [1.1026715] [-0.23339635]\n",
            "400 0.004828958 [1.0807091] [-0.18347079]\n",
            "500 0.002983996 [1.0634446] [-0.14422466]\n",
            "600 0.0018439307 [1.0498734] [-0.11337379]\n",
            "700 0.0011394335 [1.039205] [-0.08912207]\n",
            "800 0.00070410006 [1.0308186] [-0.07005789]\n",
            "900 0.00043509385 [1.0242263] [-0.05507192]\n",
            "1000 0.00026885775 [1.0190438] [-0.04329151]\n",
            "1100 0.00016613748 [1.0149702] [-0.03403098]\n",
            "1200 0.00010266373 [1.011768] [-0.02675139]\n",
            "1300 6.344064e-05 [1.0092508] [-0.02102907]\n",
            "1400 3.9201852e-05 [1.007272] [-0.01653077]\n",
            "1500 2.4224451e-05 [1.0057163] [-0.01299478]\n",
            "1600 1.4969805e-05 [1.0044937] [-0.01021512]\n",
            "1700 9.250473e-06 [1.0035325] [-0.00803011]\n",
            "1800 5.716185e-06 [1.002777] [-0.00631251]\n",
            "1900 3.5326857e-06 [1.0021831] [-0.00496238]\n",
            "2000 2.1834978e-06 [1.0017163] [-0.00390122]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9sp4wxgOlXuf",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 399
        },
        "outputId": "e003d6da-6a0b-461a-c370-4497e93cb35e"
      },
      "source": [
        "# placeholders for a tensor that will be always fed using feed_dict\n",
        "X = tf.placeholder(tf.float32, shape=[None])\n",
        "Y = tf.placeholder(tf.float32, shape=[None])\n",
        "W = tf.Variable(tf.random_normal([1]), name=\"weight\")\n",
        "b = tf.Variable(tf.random_normal([1]), name=\"bias\")\n",
        "\n",
        "# Our hypothesis is X * W + b\n",
        "hypothesis = X * W + b\n",
        "\n",
        "# cost/loss function\n",
        "cost = tf.reduce_mean(tf.square(hypothesis - Y))\n",
        "\n",
        "# optimizer\n",
        "train = tf.train.GradientDescentOptimizer(learning_rate=0.01).minimize(cost)\n",
        "\n",
        "sess = tf.Session()\n",
        "\n",
        "sess.run(tf.global_variables_initializer())\n",
        "\n",
        "for step in range(2001):\n",
        "  _, cost_val, W_val, b_val = sess.run(\n",
        "      [train, cost, W, b], feed_dict={X: [1, 2, 3, 4, 5], Y: [2.1, 3.1, 4.1, 5.1, 6.1]}\n",
        "  )\n",
        "  \n",
        "  if step % 100 == 0:\n",
        "    print(step, cost_val, W_val, b_val)"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0 43.412872 [-0.08347993] [-0.45086482]\n",
            "100 0.12561211 [1.2293205] [0.27207997]\n",
            "200 0.06380682 [1.1634408] [0.50992626]\n",
            "300 0.032411713 [1.1164873] [0.67944396]\n",
            "400 0.016464088 [1.0830225] [0.8002623]\n",
            "500 0.008363207 [1.0591716] [0.88637155]\n",
            "600 0.0042482377 [1.0421729] [0.94774306]\n",
            "700 0.0021579606 [1.0300573] [0.9914836]\n",
            "800 0.0010961725 [1.0214224] [1.0226582]\n",
            "900 0.00055682845 [1.0152682] [1.0448769]\n",
            "1000 0.00028285675 [1.010882] [1.0607125]\n",
            "1100 0.00014368803 [1.007756] [1.0719985]\n",
            "1200 7.2987554e-05 [1.0055279] [1.080043]\n",
            "1300 3.707467e-05 [1.0039397] [1.0857761]\n",
            "1400 1.8834053e-05 [1.002808] [1.0898621]\n",
            "1500 9.565597e-06 [1.0020012] [1.092775]\n",
            "1600 4.858891e-06 [1.0014262] [1.0948508]\n",
            "1700 2.467838e-06 [1.0010165] [1.09633]\n",
            "1800 1.2538724e-06 [1.0007244] [1.0973841]\n",
            "1900 6.3714623e-07 [1.0005164] [1.0981352]\n",
            "2000 3.239107e-07 [1.0003682] [1.0986706]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eGBybcdyrdKm",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 72
        },
        "outputId": "af3f5662-ddc5-4434-f3dd-dbe5c492eb04"
      },
      "source": [
        "# Testing our model\n",
        "print(sess.run(hypothesis, feed_dict={X: [5]}))\n",
        "print(sess.run(hypothesis, feed_dict={X: [2.5]}))\n",
        "print(sess.run(hypothesis, feed_dict={X: [1.5, 3.5]}))\n"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[6.1005116]\n",
            "[3.5995913]\n",
            "[2.5992231 4.5999594]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UrwIsw2orvjw",
        "colab_type": "text"
      },
      "source": [
        "## How to minimize cost\n",
        "\n",
        "<img width=\"278\" alt=\"descent\" src=\"https://user-images.githubusercontent.com/51468250/67454541-7bc2bb00-f665-11e9-8aa3-bd9fc673233e.PNG\">\n",
        "\n",
        "-> 미분, 2차원 곡선의 형태로 나타나는데 기울기가 양수면 왼쪽으로 w를 변경시키고, 기울기가 음수면 오른쪽으로 w를 변경시켜 minimum값으로 도달하게 함."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FZgVT39qOufF",
        "colab_type": "text"
      },
      "source": [
        "### cost function visualization"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N2lXRJS4G-Q_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# H(x) = Wx\n",
        "import tensorflow as tf\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "X = [1, 2, 3]\n",
        "Y = [1, 2, 3]\n",
        "\n",
        "W = tf.placeholder(tf.float32)\n",
        "\n",
        "# Our hypothesis for linear model X * W\n",
        "hypothesis = X * W"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tmMi5xaHIdEI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# cost/loss function\n",
        "cost = tf.reduce_mean(tf.square(hypothesis - Y))\n",
        "\n",
        "# Variables for plotting cost function\n",
        "W_val = []\n",
        "cost_val = []"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9LUy-stQMA78",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Launch the graph in a session.\n",
        "sess = tf.Session()\n",
        "sess.run(tf.global_variables_initializer())\n",
        "\n",
        "for i in range(-30, 50):\n",
        "  feed_W = i * 0.1\n",
        "  curr_cost, curr_W = sess.run([cost, W], feed_dict={W: feed_W})\n",
        "  W_val.append(curr_W)\n",
        "  cost_val.append(curr_cost)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NSTw7LAbNKIk",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 265
        },
        "outputId": "8c7c1f0b-e2e8-44ee-9f43-78e9792dc9cf"
      },
      "source": [
        "plt.plot(W_val, cost_val)\n",
        "plt.show()"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXAAAAD4CAYAAAD1jb0+AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjEsIGh0\ndHA6Ly9tYXRwbG90bGliLm9yZy8QZhcZAAAgAElEQVR4nO3dd3yV5f3/8dcnO5BFIAmZhD1kBIgB\nREEZVgVZakURcbRoa61Vq9WfHbbWOqvVrxNnXODCuhBEBEFBIGwwQMggCSM7kAGZ1++PHCy1AU4g\n59xnfJ6PRx5n5CT3WyRv7lznuq9LjDEopZRyPz5WB1BKKXV6tMCVUspNaYErpZSb0gJXSik3pQWu\nlFJuys+ZB+vSpYtJTk525iGVUsrtbdiwodQYE/XT551a4MnJyWRkZDjzkEop5fZEZG9rz+sQilJK\nuSktcKWUclNa4Eop5aa0wJVSyk1pgSullJvSAldKKTelBa6UUm7KLQr8860HeHttq9MglVLKa7lF\ngS/adoDHl+yirrHJ6ihKKeUy3KLAZ6YlUlHbwJIdRVZHUUopl+EWBT66ZxcSI4NZsC7f6ihKKeUy\n3KLAfXyEK1MTWZ1dRl5pjdVxlFLKJbhFgQNckZqIr4+wYH2B1VGUUsoluE2Bx4QFcUHfaD7YUEhD\nU7PVcZRSynJuU+AAV6UlUlpdx7JMfTNTKaXcqsDH9omia1gQ89fpMIpSSrlVgfv5+vDz1ARWZpVQ\nWFFrdRyllLLUKQtcRPqKyObjPg6LyO9EJFJElopIlu22kzMC//zsRADeyyh0xuGUUuqMbC2s5LLn\nV7OnuLrdv/cpC9wYs8sYk2KMSQGGA7XAR8A9wDJjTG9gme2xwyV06sCY3lG8uz6fRn0zUynl4t5Z\nm88P+w8THRbY7t+7rUMo44FsY8xeYCqQbns+HZjWnsFOZtaIJIoO1/H1zmJnHVIppdrs8NEGPt68\nnylD4ggL8m/379/WAp8JzLfdjzHGHLDdPwjEtFuqUxjXL5quYUG8vVavzFRKua5/b9rHkYYmZo1M\ncsj3t7vARSQAmAK8/9PPGWMMYE7wdXNFJENEMkpKSk476PH8fH248uxEVmaVUFCub2YqpVyPMYZ3\n1uYzKD6cwQkRDjlGW87ALwY2GmOOTcIuEpFYANttq+MZxph5xphUY0xqVFTUmaU9zsy0RASYr+uj\nKKVc0Mb8CnYerGLWCMecfUPbCvwq/jN8AvAJMMd2fw7wcXuFskdseDDj+sXwXkYB9Y36ZqZSyrW8\n/X0+IYF+XDokzmHHsKvARaQjMBFYeNzTDwMTRSQLmGB77FSzRiZRWl3Plz8cdPahlVLqhCpq6vls\n2wGmD42nY6Cfw45j13c2xtQAnX/yXBkts1IsM6Z3FAmdgnlnbT6TBzvuXzmllGqLDzcWUt/YzNUO\nHD4BN7sS86d8fYSr0pJYnV1Gdkn7T5JXSqm2Ovbm5bCkCPrHhjn0WG5d4ABXpCbg5yO8o1MKlVIu\nYE1OGTmlNVw9opvDj+X2BR4dGsRFA7vyfkYBR+p1z0yllLXeXLOXiA7+TB4c6/BjuX2BA8we2Y3D\nRxv5dMt+q6MopbzYwUNH+fKHIq5MTSTI39fhx/OIAk/rHknfmFDe+D6PlmuKlFLK+eavy6fZGGY5\nYfgEPKTARYRrRnVj+77DbC6otDqOUsoLNTQ1M39dPuf3iSKpcwenHNMjChxg+tB4QgL9eHPNXquj\nKKW80Jc7iiiuqmP2KOecfYMHFXhIoB8zhsXz2dYDlNfUWx1HKeVl3vw+j8TIYMb2iXbaMT2mwAGu\nGdmN+qZm3tWd65VSTrS7qIrvc8qZNaIbvj7itON6VIH3iQllZI9I3l67l6ZmfTNTKeUcb32/lwA/\nH36emujU43pUgQPMHplMYcURVuzSzR6UUo5XXdfIwo37mDw4lsiOAU49tscV+IVnxdA1LIjXV+dZ\nHUUp5QU+3FBIdV0jc0YlO/3YHlfg/r4+zBqRxKqsUodsIqqUUsc0NxvS1+SRkhjBkETHbNpwMh5X\n4ABXjUgiwNeHN9bkWR1FKeXBVu0pJaekhutHJ1tyfI8s8C4hgUweEsuHGwqpOtpgdRyllIdKX51H\nVGggFw90/LonrfHIAge47pxkauqb+GBDodVRlFIeKK+0huW7irk6LYkAP2uq1GMLfHBCBMOSIkhf\nnUezTilUSrWzN9bsxc9HHLrn5al4bIEDzDknmbyyWr7JKrE6ilLKg9TUNfJ+RgGXDIolOizIshz2\n7okZISIfiMhOEckUkVEiEikiS0Uky3bbydFh2+rigbFEhQaSrlMKlVLtaOHGQqrqGplzTrKlOew9\nA38KWGyM6QcMATKBe4BlxpjewDLbY5cS4OfDNSO6sWJXCTm65ZpSqh00NxteX53HkIRwhlowdfB4\npyxwEQkHxgCvABhj6o0xlcBUIN32snRgmqNCnomrbVMK9cIepVR7WJlVQnZJDdeNTkbEeeuetMae\nM/DuQAnwmohsEpGXRaQjEGOMOWB7zUEgprUvFpG5IpIhIhklJc4fi44KDWRKShzvZxRyqFanFCql\nzsyr3+URHRrIpEFxVkexq8D9gGHA88aYoUANPxkuMS3b4LQ61cMYM88Yk2qMSY2KijrTvKflhtHd\nOdLQxIL1uvGxUur0ZRVVsXJ3CdeO6mbZ1MHj2ZOgECg0xqy1Pf6AlkIvEpFYANuty64eNSAujFE9\nOpO+Oo/Gpmar4yil3NSr3+UR6OfjlB3n7XHKAjfGHAQKRKSv7anxwA/AJ8Ac23NzgI8dkrCd3HBu\nd/YfOsriHQetjqKUckMVNfUs3FjIjGHxTl918ET87HzdrcDbIhIA5ADX01L+74nIjcBe4OeOidg+\nxveLplvnDrz6bS6TB1s/dqWUci/vrMunrrGZG0Z3tzrKj+wqcGPMZiC1lU+Nb984juPjI1x/TjL3\nf/oDm/IrGJrkctPWlVIuqr6xmTfW5HFe7y70jgm1Os6PrB+Fd6LLUxMJDfTj1e/yrI6ilHIjX2w/\nQNHhOm4413XOvsHLCjwk0I+ZaYks2naAfZVHrI6jlHIDxhhe+TaXnlEdGdvbmpl0J+JVBQ5wnW38\n6vXvci1OopRyB2tzy9laeIgbz+2BjxM3LLaH1xV4fEQwkwbFMn9dAYd1rXCl1Cm8tDKHzh0DmDEs\n3uoo/8PrChzgl+f1oLqukXfXFVgdRSnlwvYUV7FsZzHXjkomyN/X6jj/wysLfFBCOCN7RPLqd7k0\n6IU9SqkTeOXbXAL9fLhmpHVrfp+MVxY4wNwxPThw6Cifbz1w6hcrpbxOSVUdH27cx+XDE+gcEmh1\nnFZ5bYGf3yeaXtEhvLQqh5alXJRS6j/eXJNHQ1MzN7rY1MHjeW2B+/gIvzi3Ozv2H2ZNdpnVcZRS\nLuRIfRNvfL+XCf1j6BEVYnWcE/LaAgeYNjSeLiEBzFuVY3UUpZQL+WBDAZW1Dcwd08PqKCfl1QUe\n5O/LnFHJrNhVws6Dh62Oo5RyAY1Nzby0KpeUxAhSu7n2khteXeAAs0d1o0OALy9+o2fhSin4YvtB\n8struXlsT8t33DkVry/wiA4BXJWWxCdb9lNQXmt1HKWUhYwxvPBNNj2iOnLhgFY3GXMpXl/gAL84\nrzs+0jLnUynlvb7dU8qO/Ye5aYzrXTbfGi1wIDY8mKkp8SxYn095Tb3VcZRSFnl+RTYxYYFMG+p6\nl823Rgvc5uaxPTja0Ey67l6vlFfaWljJ6uwybhjdnUA/17tsvjVa4Da9okOZ0D+G9DV51NY3Wh1H\nKeVkL3yTTWiQH1ePcM3L5ltjV4GLSJ6IbBORzSKSYXsuUkSWikiW7da159vY4Vfn96SytoEFusiV\nUl4lt7SGL7YfZPbIboQG+Vsdx25tOQO/wBiTYow5trXaPcAyY0xvYJntsVsb3q0TacmRvLQqh/pG\nXeRKKW/x4jfZ+Pv6cN3oZKujtMmZDKFMBdJt99OBaWcex3q/vqAnBw4d5d+b9lkdRSnlBPsrj/Dh\nxkKuTE0kOjTI6jhtYm+BG+BLEdkgInNtz8UYY44t5XcQcP1Jk3YY2yeKgfFhPP9NNk3NusiVUp6u\nZUE7uGmsa1823xp7C/xcY8ww4GLgFhEZc/wnTctyfq22nYjMFZEMEckoKSk5s7ROICLccn4vcktr\n+HybLjWrlCcrra5j/rp8pqbEk9Cpg9Vx2syuAjfG7LPdFgMfAWlAkYjEAthui0/wtfOMManGmNSo\nKNfaEPREfnZWV3pFh/Dc8j0061m4Uh7r1W9zqWts5tcX9LQ6ymk5ZYGLSEcRCT12H7gQ2A58Asyx\nvWwO8LGjQjqbj4/w6/N7svNgFV/vbPXfJaWUmzt0pIE31+zlkoGx9HThJWNPxp4z8BjgWxHZAqwD\nPjfGLAYeBiaKSBYwwfbYY0wZEkdiZDDPLN+jGz4o5YHeWJ1HVV2j2559A/id6gXGmBxgSCvPlwHj\nHRHKFfj5+nDz2J7c99F2VmeXMbpXF6sjKaXaSU1dI69+l8u4ftGcFRdudZzTpldinsRlwxKICQvk\n6WVZVkdRSrWjd9bmU1HbwC1ufPYNWuAnFeTvy01jerI2t5y1ObrtmlKe4Eh9Ey+uzGZ0r84M7xZp\ndZwzogV+ClePSKJLSCBP6Vm4Uh7h7bV7Ka2u57bxfayOcsa0wE8hyN+Xm8f2YHV2Gevzyq2Oo5Q6\nA0cbmnhxZQ6jenQmrbt7n32DFrhdZo3oRpeQAB0LV8rNzV+XT0lVHbdN6G11lHahBW6H4ABf5o7p\nwaqsUjbsrbA6jlLqNBxtaOKFb7JJ6x7JyB6drY7TLrTA7XTNyG5EdgzQsXCl3NS76wsoOlzH78Z7\nxtk3aIHbrUOAH788rwcrd5ewKV/PwpVyJ3WNTTy/IpuzkzsxqqdnnH2DFnibXDuqG506+PPkV3oW\nrpQ7WbCugIOHj3Lb+D6IuP5mxfbSAm+DjoF+3DS2Jyt3l5ChM1KUcgtHG5p4dvke0pIjGd3Lc86+\nQQu8za4d1TIj5Ymlu62OopSyw1vf76W4qo47LvSss2/QAm+zDgF+/Or8XqzOLmNNtl6dqZQrq61v\n5IVvWq669JSZJ8fTAj8Ns0YkERMWyBNLd+lKhUq5sPTVLVdd3jGxr9VRHEIL/DQE+fvymwt6sT6v\nglVZpVbHUUq1oupoAy+uzOb8vlEM79bJ6jgOoQV+mn5+diLxEcH8c+luPQtXygW99l0elbUN3DHR\n/dc8OREt8NMU6OfLreN6saWgkmWZumuPUq7kUG0DL63KYUL/GAYnRFgdx2G0wM/AZcMT6N6lI49/\nuUv3zlTKhTz/TTbVdY3ceaHnnn2DFvgZ8ff14faJfdh5sIpPtuy3Oo5SCig+fJTXV+cydUgc/WPD\nrI7jUHYXuIj4isgmEfnM9ri7iKwVkT0i8q6IBDgupuuaPCiWAbFhPLF0N/WNzVbHUcrrPf11Fo1N\nhts9eOz7mLacgd8GZB73+BHgSWNML6ACuLE9g7kLHx/hrov6kl9ey7sZBVbHUcqr7S2rYcG6Amam\nJdKtc0er4zicXQUuIgnAJOBl22MBxgEf2F6SDkxzREB3cH6fKNKSI3l6WRa19Y1Wx1HKaz2xdDd+\nvsJvx3nOioMnY+8Z+L+Au4FjYwSdgUpjzLG2KgTiW/tCEZkrIhkiklFSUnJGYV2ViHD3RX0pqarj\n9dV5VsdRyitlHjjMJ1v2c/3o7kSHBVkdxylOWeAiMhkoNsZsOJ0DGGPmGWNSjTGpUVFRp/Mt3EJq\nciTj+kXzwopsDtU2WB1HKa/z+JJdhAb6cfMY995pvi3sOQMfDUwRkTxgAS1DJ08BESLiZ3tNArDP\nIQndyF0/60tVXSPPrdhjdRSlvMr3OWUs21nMzef3JLyDv9VxnOaUBW6MudcYk2CMSQZmAl8bY2YB\ny4HLbS+bA3zssJRuon9sGJcNS+C11XkUVtRaHUcpr2CM4aFFmcSGB3HD6O5Wx3GqM5kH/gfgDhHZ\nQ8uY+CvtE8m93TGxDwI88aUuN6uUM3y+7QBbCg9x54V9CfL3tTqOU7WpwI0xK4wxk233c4wxacaY\nXsaYK4wxdY6J6F7iIoK54dzufLR5H9v3HbI6jlIerb6xmUcX76Jf11CmD211HoVH0ysxHeBX5/ck\nItifh7/YqQtdKeVAb32/l/zyWu65uB++Pp61WYM9tMAdICzIn1vH9ebbPaWs1OVmlXKIQ0ca+L+v\nsxjdqzNj+3juDLeT0QJ3kGtGdiMpsgMPLcqkSRe6UqrdvfBNNhW1Ddx7cX+P2yrNXlrgDhLg58Pd\nF/Vl58EqPtigl9gr1Z4Kymt55dtcpqXEMTA+3Oo4ltECd6BJg2IZ3q0Tjy3ZTXWdXmKvVHt5ZPFO\nfATuvqif1VEspQXuQCLCnycPoLS6jueW68U9SrWHjLxyPtt6gLljehIXEWx1HEtpgTvYkMQIpg+N\n5+Vvcyko14t7lDoTzc2GBz77gZiwQG4e28PqOJbTAneCuy/qi4+0/NqnlDp9H2/Zx5bCQ9z1s350\nCPA79Rd4OC1wJ4gND2bumJ58tvUAG/aWWx1HKbd0pL6JRxfvYlB8ODO88KKd1miBO8nNY3sQExbI\n3z79QffPVOo0vLgymwOHjvKnyQPw8cKLdlqjBe4kHQL8uOfifmwpPMQHGwutjqOUWymsqOX5FdlM\nGhRLWvdIq+O4DC1wJ5qWEs+wpAgeXbyTw0d1zXCl7PWPRZmIwP+b1N/qKC5FC9yJRIS/TR1IWU09\nT32VZXUcpdzCd3tKWbTtILec34t4L582+FNa4E42MD6cmWcnkb46j6yiKqvjKOXSGpqa+eunO0iM\nDOaXY3Ta4E9pgVvg9xf2oUOAL/d/ukNXK1TqJN5cs5fdRdX8adIAr1vr2x5a4BboHBLInRf25bs9\nZSzZcdDqOEq5pNLqOp78ajdj+kQxcUCM1XFckha4RWaNSKJf11D+9ukP1NbrOilK/dTDX+zkSH0T\nf548wGtXGzwVe3alDxKRdSKyRUR2iMhfbc93F5G1IrJHRN4VkQDHx/Ucfr4+PDBtIPsPHeXpZbpO\nilLHW5dbzgcbCvnlmB70ig6xOo7LsucMvA4YZ4wZAqQAF4nISOAR4EljTC+gArjRcTE909nJkVwx\nPIGXV+XoG5pK2TQ0NfOnf28nPiKY347rbXUcl2bPrvTGGFNte+hv+zDAOOAD2/PpwDSHJPRw917S\nn5AgP/747+36hqZSwKvf5rKrqIr7p5xFcIC+cXkydo2Bi4iviGwGioGlQDZQaYw5NnhbCLS6OIGI\nzBWRDBHJKCkpaY/MHiWyYwB/uKgfa3PL+WjTPqvjKGWp/ZVH+NdXWUzoH6NvXNrBrgI3xjQZY1KA\nBCANsHsVdWPMPGNMqjEmNSrKO/etO5UrUxMZlhTBg59ncqhWr9BU3uuvn+7AYPjLpQOsjuIW2jQL\nxRhTCSwHRgERInJsPccEQE8fT5OPj/D3aYOoqK3nkSW65KzyTssyi1iyo4jfju9NYmQHq+O4BXtm\noUSJSITtfjAwEcikpcgvt71sDvCxo0J6gwFxYdx4bnfeWZvPulxdclZ5l+q6Rv747+30iQnhF+fq\nFZf2sucMPBZYLiJbgfXAUmPMZ8AfgDtEZA/QGXjFcTG9w+0T+5DQKZh7F26lrrHJ6jhKOc3jS3Zx\n8PBRHpoxmAA/vTzFXvbMQtlqjBlqjBlsjBlojPmb7fkcY0yaMaaXMeYKY0yd4+N6tg4Bfjw4fRDZ\nJTU8uzzb6jhKOcXG/ArS1+Qxe2Q3hnfrZHUct6L/1LmYsX2imJYSx/Mr9rBb54YrD1ff2My9H24j\nJjSIu37W1+o4bkcL3AX9afIAQgL9uHfhNt29R3m0l1blsKuoigemDSQ0yN/qOG5HC9wFdQ4J5I+T\nBrBhbwVvfr/X6jhKOUR2STVPLcvikkFddc73adICd1EzhsUzpk8UjyzeSX5ZrdVxlGpXTc2Gu97f\nQrC/L/dfepbVcdyWFriLEhEemjEIHxH+8OFWHUpRHuW173LZmF/JX6ecRXRYkNVx3JYWuAuLjwjm\nvkn9WZNTxjvr8q2Oo1S7yC2t4bElu5jQP4apKXFWx3FrWuAububZiZzbqwsPLcqkoFyHUpR7OzZ0\nEujnwz+mD9R1vs+QFriLExEevmwQAPcs3KorFiq3lr46j4y9FdyvQyftQgvcDSR06sD/m9Sf7/aU\n8dZaHUpR7imnpJpHl+xkXL9opg9tdfFS1UZa4G7i6rQkzuvdhX98nkluaY3VcZRqk8amZm5/bwtB\n/r48PGOQDp20Ey1wNyEiPHb5EAL8fLj93c00NjVbHUkpuz27PJstBZU8OG2QDp20Iy1wN9I1PIi/\nTxvI5oJKnluha6Uo97CloJKnv85i+tB4Jg2OtTqOR9ECdzOXDoljakocTy/LYmthpdVxlDqpI/VN\n3P7eZqJDA7l/il6w0960wN3Q36YMpEtIILe/u5kj9brsrHJdD3+RSU5JDY9fMYTwYF3rpL1pgbuh\n8A7+/PPnQ8guqeGBz3+wOo5SrVqWWUT6mr3cMLo7o3t1sTqOR9ICd1Oje3XhprE9eGdtPou3H7A6\njlL/pejwUe76YCsDYsP4w8W6TKyjaIG7sTsn9mVwQjh3f7CVfZVHrI6jFNByteWx4b2nrxpKoJ+v\n1ZE8lha4Gwvw8+HpmUNbfmAW6NRC5RpeXJnN6uwy7p8ygF7RIVbH8Wj2bGqcKCLLReQHEdkhIrfZ\nno8UkaUikmW71b2QLJDcpSMPTBvIurxynlm+x+o4ysttyq/gn1/uZtLgWH6emmh1HI9nzxl4I3Cn\nMWYAMBK4RUQGAPcAy4wxvYFltsfKAjOGJTB9aDxPL8tidXap1XGUlzpU28Bv3tlE17Ag/jFdr7Z0\nBns2NT5gjNlou18FZALxwFQg3faydGCao0KqU3tg2kCSu3Tkt/M3U3z4qNVxlJdpbjbc+f5miquO\n8uysYTpl0EnaNAYuIsnAUGAtEGOMOTb94SDQ6p5IIjJXRDJEJKOkpOQMoqqTCQn04/lZw6mua+DW\n+Zt0PFw51bxVOXyVWcx9l/QnJTHC6jhew+4CF5EQ4EPgd8aYw8d/zrSscdrqOqfGmHnGmFRjTGpU\nVNQZhVUn17drKH+fNoi1ueU8+dVuq+MoL7E2p4zHluxi0qBY5pyTbHUcr2JXgYuIPy3l/bYxZqHt\n6SIRibV9PhYodkxE1RaXD0/gytREnl2ezfKd+r9EOVZJVR23zt9EYqdgHr5Mx72dzZ5ZKAK8AmQa\nY5447lOfAHNs9+cAH7d/PHU6/jr1LPp1DeV3727WDZGVwzQ0NXPr/I0cOtLAc7OGExqk497OZs8Z\n+GhgNjBORDbbPi4BHgYmikgWMMH2WLmAIH9fXpw9HGMMc9/MoLa+0epIygM9tGgn3+eU84/pgxgQ\nF2Z1HK9kzyyUb40xYowZbIxJsX0sMsaUGWPGG2N6G2MmGGPKnRFY2adb5448fdVQdhVVcdcHuhWb\nal8LNxby6ne5XHdOMpcNT7A6jtfSKzE92Pl9o7nrZ335fOsBXlyZY3Uc5SG27zvEvQu3MaJ7JPdN\n6m91HK+mBe7hfjW2J5MGxfLo4p2s3K3TONWZKauu46Y3N9C5YwDPzhqGv69WiJX0T9/DiQiPXj6Y\nPjGh3PLORvYUV1sdSbmpusYmbn5rAyXVdbwwezhdQgKtjuT1tMC9QMdAP166NpUAXx9uTF9PRU29\n1ZGUmzHGcO/CbazPq+CfVwxhcIJerOMKtMC9RGJkB+ZdO5wDlUe56a0N1DfqlZrKfs+tyGbhxn3c\nPqEPlw6JszqOstEC9yLDu0Xy6OWDWZdbzn0fbdOZKcouX2w7wGNLdjFlSBy/Hd/L6jjqOH5WB1DO\nNW1oPDkl1Tz99R66R3Xk1+frD6Q6sc0Fldz+3maGJUXw6OWD9UpLF6MF7oV+N6EPuWW1PLp4F7Hh\nQUwfqvN41f/KK63hhtfXExUayIuzUwny1511XI0WuBfy8REev2IwJVVHuev9rXQJCeS83rrQmPqP\nkqo6rn11HcYY0q9PIypUZ5y4Ih0D91KBfr68ODuVXtEh3PzmBrbvO2R1JOUiauoauTF9PcVVR3nl\nurPpEaXborkqLXAvFh7sz+vXpxEe7M/1r6+noFwXvvJ2DU3N3PLORrbvO8QzVw1jWJLulOjKtMC9\nXNfwINJvSKO+sZlZL6+lSHfz8VpNzYY73tvCil0lPDh9EBMGtLpHi3IhWuCK3jGhvH792ZRV13HN\ny2sp1wt9vI4xhvs+2sanW/Zzz8X9uCotyepIyg5a4AqAoUmdeHnO2eSX1zLn1XVUHW2wOpJyEmMM\nD36eyYL1Bfzmgl7cPLan1ZGUnbTA1Y9G9ezM89cMI/PAYW58XdcR9xZPLcvi5W9bloa988I+VsdR\nbaAFrv7LuH4x/GtmChl7y7nh9fVa4h7u6WVZ/OurLC4fnsCfJw/QC3XcjBa4+h+TB8fx5JUprMvV\nEvdkT32VxRNLdzNjWDyPXDYYHx8tb3djz56Yr4pIsYhsP+65SBFZKiJZtluda+RhpqbE/1ji1722\nnpo6LXFP8uTS3Tz51W4uG5bAY5cPwVfL2y3Zcwb+OnDRT567B1hmjOkNLLM9Vh5mako8/5o5lIy8\ncq5/bb2+sekBjDE88eUunlqWxRXDE3j08sFa3m7Mnj0xVwI/3e9yKpBuu58OTGvnXMpFTBkSx1Mz\nh7Ihv4JZOsXQrTU3G/766Q88/fUerkxN5JHLtLzd3emOgccYYw7Y7h8ETjjjX0TmikiGiGSUlOiW\nXu7o0iFxzJs9nF0Hq7jihdUcOHTE6kiqjRqamvn9+1t4fXUevzi3Ow/NGKRj3h7gjN/ENC2LSp9w\nYWljzDxjTKoxJjUqShdMclfj+8fwxg1pFB+u4/Ln15BToluzuYujDU386q2NLNy0j99f2If7JvXX\n8vYQp1vgRSISC2C7LW6/SMpVjejRmflzR3K0oYkrXljDpvwKqyOpU6isrefaV9axbGcRD0w9i9+M\n661TBT3I6Rb4J8Ac2/05wMftE0e5uoHx4bx/8yg6Bvoxc973LN5+4NRfpCyxt6yGGc+tZnNhJU/P\nHMrsUclWR1LtzJ5phPOBNSJVuC0AAArZSURBVEBfESkUkRuBh4GJIpIFTLA9Vl6iR1QIH/36HAbE\nhfGrtzfy8qoc3Z7NxWzYW8H051ZTUVvPO78YoftYeqhTbuhgjLnqBJ8a385ZlBvpHBLI/F+O5I73\nNvP3zzPJK6vhL5eehb+vXhtmtU+37Of3728hNjyI165Po3uXjlZHUg6iP23qtAX5+/LMVcO4aWwP\n3vo+n1kvraWkqs7qWF6rqdnw0BeZ3Dp/E4MTwln469Fa3h5OC1ydER8f4d6L+/PUzBS27qtkyjPf\nsqWg0upYXqeytp7rXlvHi9/kcM3IJN7+xUgiOwZYHUs5mBa4ahdTU+L54OZz8BHhihfX8N76Ah0X\nd5Id+w8x5ZnvWJtTziOXDeLv0wYR4Kc/2t5A/y+rdjMwPpxPbz2Xs5M7cfeHW7n93c1U6xoqDmOM\nIX11HtOfXU1dYxMLbhrJlWfrRgzeRHelV+0qsmMAb9wwgmeX7+FfX+1mS+Eh/u+qoQyMD7c6mkc5\nVNvA3R9uYcmOIsb1i+bxK4bokIkX0jNw1e58fYTfju/NgrmjOFLfxIznVvPSyhyamnVIpT2szi7l\nkqdX8fXOYv44qT8vX5uq5e2ltMCVw6R1j+SL285jbN8oHlyUyZUvriG3tMbqWG6rtr6Rv3y8natf\nWou/r/D+zefwi/N66GXxXkwLXDlUp44BzJs9nCd+PoRdRVVc/NRKXv8ul2Y9G2+T9XnlXPzUKtLX\n7OW6c5JZdNt5pCRGWB1LWUzHwJXDiQgzhiVwTs8u3LNwK/d/+gMfb9nPA1MH6tj4KVTU1PPI4p0s\nWF9AYmQwC+aOZGSPzlbHUi5CnDnVKzU11WRkZDjteMr1GGNYuHEf/1iUSUVtPdeOSuaOC/sQFuRv\ndTSX0txseH9DAQ9/sZPDRxu5YXQyv5vQh46Bes7ljURkgzEm9afP698G5VQiwmXDE5jQP4bHv9xF\n+po8Pt92gDsn9uHy4Qn46aX4ZOSV8+CiTDblV3J2cicemDaQfl3DrI6lXJCegStLbS2s5C+f7GBT\nfiW9o0O45+J+jOsX7ZVLnmaXVPPo4p0s2VFEdGggd/2sL5cPT/DKPwv13050Bq4FrixnjGHJjoM8\nungXOaU1pHWP5LbxvTmnZ2evKK/8slqe/2YP72UUEuzvy01jenDjed3pEKC/IKsWWuDK5TU0NbNg\nfQHPfJ1F0eE6UhIjuHVcL489I88qquK5Fdl8smU/vj7CVWcncuv43nQJCbQ6mnIxWuDKbdQ1NvHB\nhkKeX5FNYcUR+saEcu053ZiWEu/2b+I1NxtW7SnlzTV5LNtZTJCfL9eMTOKX5/UgOizI6njKRWmB\nK7fT0NTMJ5v388q3ufxw4DChgX5cNjyBq0ck0Scm1Op4bVJeU8/CjYW89f1e8spq6RISwNVpSVw3\nurteRalOSQtcuS1jDBvzK3lzTR6Lth2kvqmZ/rFhTEuJ49IhccRFBFsdsVU1dY18lVnEx5v3s3J3\nCY3NhtRunZg9qhsXD4zVFQOV3bTAlUcora7jsy37+ffm/Wy2rTs+NCmCC/pGc37fKAbGhVt6afm+\nyiOs2FXM8p0lfLenlCMNTcSFBzElJZ5pQ+N0OqA6LQ4pcBG5CHgK8AVeNsacdG9MLXDVnvaW1fDJ\n5v18tbOYrYWVGANdQgIY0b0zw7p1YlhSBGfFhTvsTNcYQ25pDRvzK9mYX8H63HKyiqsBiI8IZly/\naC4dEkdqt066Xok6I+1e4CLiC+wGJgKFwHrgKmPMDyf6Gi1w5Sil1XWs3F3CN7tLyMirYF/lEQAC\n/HzoGRVCr+gQekWF0DO6I13DgogKDSQ6NIjgAN+Tft+GpmbKqusprjpK8eE68spq2FNczZ7iarKK\nqzl0pAGA0EA/UpIiGNM7igv6RdEzKsQjZ84oazjiSsw0YI8xJsd2gAXAVOCEBa6Uo3QJCWTGsARm\nDEsA4OCho2zMr2BzQSW7i6rYlF/Bp1v2/8/XBfv7EuTvQ6CfL4H+PviIUNfQRF1jM3WNza1uSBHZ\nMYBeUSFcMiiWwQnhDEvqRK/oEHz1LFs52ZkUeDxQcNzjQmDET18kInOBuQBJSbpbiHKOruFBXDIo\nlksGxf743JH6JvLKaiiuqqP48FFKqusor663lXVLaTc1GwL9/lPqoUF+RIcFEhUSSHRYEImdgums\n87SVi3D4pFpjzDxgHrQMoTj6eEqdSHCAL/1jw+gfe+rXKuUOzuTdnX1A4nGPE2zPKaWUcoIzKfD1\nQG8R6S4iAcBM4JP2iaWUUupUTnsIxRjTKCK/AZbQMo3wVWPMjnZLppRS6qTOaAzcGLMIWNROWZRS\nSrWBXsurlFJuSgtcKaXclBa4Ukq5KS1wpZRyU05djVBESoC9p/nlXYDSdozTnlw1m6vmAtfN5qq5\nwHWzuWoucN1sbc3VzRgT9dMnnVrgZ0JEMlpbzMUVuGo2V80FrpvNVXOB62Zz1VzgutnaK5cOoSil\nlJvSAldKKTflTgU+z+oAJ+Gq2Vw1F7huNlfNBa6bzVVzgetma5dcbjMGrpRS6r+50xm4Ukqp42iB\nK6WUm3KrAheRB0Rkq4hsFpEvRSTO6kwAIvKYiOy0ZftIRCKsznSMiFwhIjtEpFlELJ9OJSIXicgu\nEdkjIvdYnecYEXlVRIpFZLvVWY4nIokislxEfrD9f7zN6kzHiEiQiKwTkS22bH+1OtPxRMRXRDaJ\nyGdWZzmeiOSJyDZbj53RJsFuVeDAY8aYwcaYFOAz4M9WB7JZCgw0xgymZaPney3Oc7ztwAxgpdVB\nbBthPwtcDAwArhKRAdam+tHrwEVWh2hFI3CnMWYAMBK4xYX+zOqAccaYIUAKcJGIjLQ40/FuAzKt\nDnECFxhjUs50LrhbFbgx5vBxDzsCLvEOrDHmS2PMsd1vv6dldyKXYIzJNMbssjqHzY8bYRtj6oFj\nG2FbzhizEii3OsdPGWMOGGM22u5X0VJI8damamFaVNse+ts+XOJnUkQSgEnAy1ZncSS3KnAAEXlQ\nRAqAWbjOGfjxbgC+sDqEi2ptI2yXKCN3ICLJwFBgrbVJ/sM2TLEZKAaWGmNcJdu/gLuBZquDtMIA\nX4rIBtum76fN5QpcRL4Ske2tfEwFMMbcZ4xJBN4GfuMquWyvuY+WX3nfdlYue7Mp9yYiIcCHwO9+\n8puopYwxTbYhzQQgTUQGWp1JRCYDxcaYDVZnOYFzjTHDaBlKvEVExpzuN3L4rvRtZYyZYOdL36Zl\nN6C/ODDOj06VS0SuAyYD442TJ9e34c/MaroR9mkQEX9ayvttY8xCq/O0xhhTKSLLaXkfweo3gkcD\nU0TkEiAICBORt4wx11icCwBjzD7bbbGIfETL0OJpvUflcmfgJyMivY97OBXYaVWW44nIRbT8ujbF\nGFNrdR4Xphtht5GICPAKkGmMecLqPMcTkahjM65EJBiYiAv8TBpj7jXGJBhjkmn5O/a1q5S3iHQU\nkdBj94ELOYN/8NyqwIGHbUMDW2n5D3eVKVXPAKHAUtvUoBesDnSMiEwXkUJgFPC5iCyxKovtjd5j\nG2FnAu+5ykbYIjIfWAP0FZFCEbnR6kw2o4HZwDjb363NtjNLVxALLLf9PK6nZQzcpabsuaAY4FsR\n2QKsAz43xiw+3W+ml9IrpZSbcrczcKWUUjZa4Eop5aa0wJVSyk1pgSullJvSAldKKTelBa6UUm5K\nC1wppdzU/wfMjZcCPi6P6AAAAABJRU5ErkJggg==\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CW0WSd6MOznU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "x_data = [1, 2, 3]\n",
        "y_data = [1, 2, 3]\n",
        "\n",
        "W = tf.Variable(tf.random_normal([1]), name='weight')\n",
        "X = tf.placeholder(tf.float32)\n",
        "Y = tf.placeholder(tf.float32)\n",
        "\n",
        "# Our hypothesis for linear model X * W\n",
        "hypothesis = X * W"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AIG3B_2rPQYM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# cost/loss function\n",
        "cost = tf.reduce_mean(tf.square(hypothesis - Y))\n",
        "\n",
        "# Minimize: Gradient Descent using derivative: W -= Learning_rate * derivative\n",
        "learning_rate = 0.1\n",
        "gradient = tf.reduce_mean((W * X - Y) * X)\n",
        "descent = W - learning_rate * gradient\n",
        "update = W.assign(descent)  #W값 갱신 op"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VEsiTZGSPxdO",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 399
        },
        "outputId": "8718a0f6-fd1a-46f6-bcb7-b65ac6b639ef"
      },
      "source": [
        "# Launch the graph in a session.\n",
        "sess = tf.Session()\n",
        "sess.run(tf.global_variables_initializer())\n",
        "\n",
        "for step in range(21):\n",
        "  sess.run(update, feed_dict={X: x_data, Y: y_data})\n",
        "  print(step, sess.run(cost, feed_dict={X: x_data, Y: y_data}), sess.run(W))"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0 0.632926 [0.6317243]\n",
            "1 0.18003221 [0.8035863]\n",
            "2 0.051209178 [0.895246]\n",
            "3 0.014566169 [0.9441312]\n",
            "4 0.0041432814 [0.9702033]\n",
            "5 0.0011785267 [0.98410845]\n",
            "6 0.00033522342 [0.9915245]\n",
            "7 9.535242e-05 [0.99547976]\n",
            "8 2.7121203e-05 [0.99758923]\n",
            "9 7.714342e-06 [0.99871427]\n",
            "10 2.1946053e-06 [0.99931425]\n",
            "11 6.2422004e-07 [0.99963427]\n",
            "12 1.7762981e-07 [0.9998049]\n",
            "13 5.056717e-08 [0.99989593]\n",
            "14 1.4363703e-08 [0.9999445]\n",
            "15 4.0987764e-09 [0.9999704]\n",
            "16 1.1661676e-09 [0.9999842]\n",
            "17 3.3061673e-10 [0.9999916]\n",
            "18 9.2727014e-11 [0.9999955]\n",
            "19 2.6526928e-11 [0.9999976]\n",
            "20 7.461883e-12 [0.99999875]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pM9ZiOW0Q4lJ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 399
        },
        "outputId": "c7d4c945-ab52-4beb-ab27-132259e0c9a1"
      },
      "source": [
        "sess = tf.Session()\n",
        "sess.run(tf.global_variables_initializer())\n",
        "\n",
        "for step in range(21):\n",
        "  cost_val, W_val, _ = sess.run([cost, W, update], feed_dict={X: x_data, Y: y_data})\n",
        "  print(step, cost_val, W_val)"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0 22.088074 [-0.1603105]\n",
            "1 6.2828293 [0.3811677]\n",
            "2 1.7871157 [0.6699561]\n",
            "3 0.50833535 [0.8239766]\n",
            "4 0.14459313 [0.90612084]\n",
            "5 0.04112871 [0.9499311]\n",
            "6 0.011698854 [0.9732966]\n",
            "7 0.003327675 [0.9857582]\n",
            "8 0.0009465401 [0.9924044]\n",
            "9 0.00026923546 [0.99594903]\n",
            "10 7.658167e-05 [0.9978395]\n",
            "11 2.1782413e-05 [0.9988477]\n",
            "12 6.1961305e-06 [0.9993855]\n",
            "13 1.7621716e-06 [0.99967223]\n",
            "14 5.013033e-07 [0.9998252]\n",
            "15 1.4264435e-07 [0.9999068]\n",
            "16 4.0554635e-08 [0.9999503]\n",
            "17 1.1543709e-08 [0.9999735]\n",
            "18 3.286285e-09 [0.9999859]\n",
            "19 9.329296e-10 [0.9999925]\n",
            "20 2.6142763e-10 [0.999996]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kGOci_WUSWu1",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 199
        },
        "outputId": "fae6f157-7dd1-494e-9d8c-4fa7b3f772fd"
      },
      "source": [
        "X = [1, 2, 3]\n",
        "Y = [1, 2, 3]\n",
        "\n",
        "W = tf.Variable(5.0)\n",
        "\n",
        "# Our hypothesis for linear model X * W\n",
        "hypothesis = X * W\n",
        "\n",
        "cost = tf.reduce_mean(tf.square(hypothesis - Y))\n",
        "\n",
        "optimizer = tf.train.GradientDescentOptimizer(learning_rate=0.1)\n",
        "train = optimizer.minimize(cost)\n",
        "\n",
        "sess = tf.Session()\n",
        "sess.run(tf.global_variables_initializer())\n",
        "\n",
        "for step in range(10):\n",
        "  W_val, _ = sess.run([W, train])\n",
        "  print(step, W_val)"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0 1.2666664\n",
            "1 1.0177778\n",
            "2 1.0011852\n",
            "3 1.000079\n",
            "4 1.0000052\n",
            "5 1.0000004\n",
            "6 1.0\n",
            "7 1.0\n",
            "8 1.0\n",
            "9 1.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Cy306iaRVDmF",
        "colab_type": "text"
      },
      "source": [
        "## Multi-varable linear regression\n",
        "\n",
        "H(x) = Wx + b\n",
        "\n",
        "H(x1,x2,x3) = w1x1 + w2x2 + w3x3 + b\n",
        "\n",
        "-> Matrix\n",
        "\n",
        "-> H(X) = XW"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p2s0EH3nfZSE",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 617
        },
        "outputId": "114faa67-3d18-4fa0-eba4-e12d3a8b29a9"
      },
      "source": [
        "# 코드 복잡함 (사용 X)\n",
        "\n",
        "import tensorflow as tf\n",
        "tf.set_random_seed(777)  # for reproducibility\n",
        "\n",
        "x1_data = [73., 93., 89., 96., 73.]\n",
        "x2_data = [80., 88., 91., 98., 66.]\n",
        "x3_data = [75., 93., 90., 100., 70.]\n",
        "\n",
        "y_data = [152., 185., 180., 196., 142.]\n",
        "\n",
        "# placeholders for a tensor that will be always fed.\n",
        "x1 = tf.placeholder(tf.float32)\n",
        "x2 = tf.placeholder(tf.float32)\n",
        "x3 = tf.placeholder(tf.float32)\n",
        "\n",
        "Y = tf.placeholder(tf.float32)\n",
        "\n",
        "w1 = tf.Variable(tf.random_normal([1]), name='weight1')\n",
        "w2 = tf.Variable(tf.random_normal([1]), name='weight2')\n",
        "w3 = tf.Variable(tf.random_normal([1]), name='weight3')\n",
        "b = tf.Variable(tf.random_normal([1]), name='bias')\n",
        "\n",
        "hypothesis = x1 * w1 + x2 * w2 + x3 * w3 + b\n",
        "\n",
        "# cost/loss function\n",
        "cost = tf.reduce_mean(tf.square(hypothesis - Y))\n",
        "\n",
        "# Minimize. Need a very small learning rate for this data set\n",
        "optimizer = tf.train.GradientDescentOptimizer(learning_rate=1e-5)\n",
        "train = optimizer.minimize(cost)\n",
        "\n",
        "# Launch the graph in a session.\n",
        "sess = tf.Session()\n",
        "# Initializes global variables in the graph.\n",
        "sess.run(tf.global_variables_initializer())\n",
        "\n",
        "for step in range(2001):\n",
        "    cost_val, hy_val, _ = sess.run([cost, hypothesis, train],\n",
        "                                   feed_dict={x1: x1_data, x2: x2_data, x3: x3_data, Y: y_data})\n",
        "    if step % 200 == 0:\n",
        "        print(step, \"Cost: \", cost_val, \"\\nPrediction:\\n\", hy_val)\n"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0 Cost:  3779.23 \n",
            "Prediction:\n",
            " [211.02502 246.67366 246.6029  267.2102  187.84448]\n",
            "200 Cost:  10.282494 \n",
            "Prediction:\n",
            " [156.30516 181.38615 182.02332 196.91463 138.14153]\n",
            "400 Cost:  9.241639 \n",
            "Prediction:\n",
            " [156.0633  181.55182 181.94904 196.86223 138.35779]\n",
            "600 Cost:  8.307734 \n",
            "Prediction:\n",
            " [155.83418 181.70876 181.87865 196.81267 138.5626 ]\n",
            "800 Cost:  7.4697633 \n",
            "Prediction:\n",
            " [155.61711 181.8574  181.81197 196.76578 138.75658]\n",
            "1000 Cost:  6.7178574 \n",
            "Prediction:\n",
            " [155.4115  181.99826 181.7488  196.7214  138.94029]\n",
            "1200 Cost:  6.043126 \n",
            "Prediction:\n",
            " [155.21666 182.1317  181.68892 196.67943 139.11426]\n",
            "1400 Cost:  5.437696 \n",
            "Prediction:\n",
            " [155.03209 182.25809 181.63217 196.6397  139.27904]\n",
            "1600 Cost:  4.894478 \n",
            "Prediction:\n",
            " [154.85722 182.37784 181.57845 196.60216 139.43507]\n",
            "1800 Cost:  4.407046 \n",
            "Prediction:\n",
            " [154.69156 182.49127 181.5275  196.5666  139.58282]\n",
            "2000 Cost:  3.9696808 \n",
            "Prediction:\n",
            " [154.5346  182.59872 181.47923 196.53302 139.72276]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bJ4WiCaVg7EQ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "1fb7dd04-571c-43c3-9f81-daf3d804b061"
      },
      "source": [
        "import tensorflow as tf\n",
        "tf.set_random_seed(777)  # for reproducibility\n",
        "\n",
        "x_data = [[73., 80., 75.],\n",
        "          [93., 88., 93.],\n",
        "          [89., 91., 90.],\n",
        "          [96., 98., 100.],\n",
        "          [73., 66., 70.]]\n",
        "y_data = [[152.],\n",
        "          [185.],\n",
        "          [180.],\n",
        "          [196.],\n",
        "          [142.]]\n",
        "\n",
        "\n",
        "# placeholders for a tensor that will be always fed.\n",
        "X = tf.placeholder(tf.float32, shape=[None, 3])\n",
        "Y = tf.placeholder(tf.float32, shape=[None, 1])\n",
        "\n",
        "W = tf.Variable(tf.random_normal([3, 1]), name='weight')\n",
        "b = tf.Variable(tf.random_normal([1]), name='bias')\n",
        "\n",
        "# Hypothesis\n",
        "hypothesis = tf.matmul(X, W) + b\n",
        "\n",
        "# Simplified cost/loss function\n",
        "cost = tf.reduce_mean(tf.square(hypothesis - Y))\n",
        "\n",
        "# Minimize\n",
        "optimizer = tf.train.GradientDescentOptimizer(learning_rate=1e-5)\n",
        "train = optimizer.minimize(cost)\n",
        "\n",
        "# Launch the graph in a session.\n",
        "sess = tf.Session()\n",
        "# Initializes global variables in the graph.\n",
        "sess.run(tf.global_variables_initializer())\n",
        "\n",
        "for step in range(2001):\n",
        "    cost_val, hy_val, _ = sess.run(\n",
        "        [cost, hypothesis, train], feed_dict={X: x_data, Y: y_data})\n",
        "    if step % 200 == 0:\n",
        "        print(step, \"Cost: \", cost_val, \"\\nPrediction:\\n\", hy_val)"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0 Cost:  45719.477 \n",
            "Prediction:\n",
            " [[337.9183 ]\n",
            " [414.6525 ]\n",
            " [403.92352]\n",
            " [442.52728]\n",
            " [316.2815 ]]\n",
            "200 Cost:  4.0098658 \n",
            "Prediction:\n",
            " [[148.3195 ]\n",
            " [186.55103]\n",
            " [179.28569]\n",
            " [197.87529]\n",
            " [142.2658 ]]\n",
            "400 Cost:  3.7966397 \n",
            "Prediction:\n",
            " [[148.42982]\n",
            " [186.47675]\n",
            " [179.32121]\n",
            " [197.88766]\n",
            " [142.17955]]\n",
            "600 Cost:  3.6035485 \n",
            "Prediction:\n",
            " [[148.53464]\n",
            " [186.40627]\n",
            " [179.35504]\n",
            " [197.8989 ]\n",
            " [142.09822]]\n",
            "800 Cost:  3.4285374 \n",
            "Prediction:\n",
            " [[148.63419]\n",
            " [186.33934]\n",
            " [179.38724]\n",
            " [197.90898]\n",
            " [142.02155]]\n",
            "1000 Cost:  3.2697773 \n",
            "Prediction:\n",
            " [[148.72879]\n",
            " [186.27582]\n",
            " [179.41791]\n",
            " [197.91806]\n",
            " [141.94926]]\n",
            "1200 Cost:  3.1255946 \n",
            "Prediction:\n",
            " [[148.81871]\n",
            " [186.21553]\n",
            " [179.44716]\n",
            " [197.92616]\n",
            " [141.88118]]\n",
            "1400 Cost:  2.994541 \n",
            "Prediction:\n",
            " [[148.90413]\n",
            " [186.15826]\n",
            " [179.475  ]\n",
            " [197.93329]\n",
            " [141.817  ]]\n",
            "1600 Cost:  2.875238 \n",
            "Prediction:\n",
            " [[148.98537]\n",
            " [186.1039 ]\n",
            " [179.50156]\n",
            " [197.93956]\n",
            " [141.75659]]\n",
            "1800 Cost:  2.7665665 \n",
            "Prediction:\n",
            " [[149.06256]\n",
            " [186.05226]\n",
            " [179.52687]\n",
            " [197.94499]\n",
            " [141.69969]]\n",
            "2000 Cost:  2.667367 \n",
            "Prediction:\n",
            " [[149.136  ]\n",
            " [186.00322]\n",
            " [179.55103]\n",
            " [197.94965]\n",
            " [141.64616]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2AvrxRn6hcVV",
        "colab_type": "text"
      },
      "source": [
        "## Logistic classification\n",
        "\n",
        "-> linear regresion으로 쓰면 문제가 있음\n",
        "\n",
        "-> 0과 1로만 분류하기 때문에 아무리 큰 값이 들어와도 y는 1보다 클 수 없음\n",
        "\n",
        "-> 0 ~ 1 사이로 출력할 수 있는 함수가 필요함\n",
        "\n",
        "-> sigmoid function (logistic function)\n",
        "\n",
        "## Cost function\n",
        "\n",
        "-> linear regression으로 가설을 세웠을 때의 cost function 같이 2차원 모양의 곡선이 아님\n",
        "\n",
        "-> 울퉁불퉁한 곡선의 형태기 때문에 시작하는 점에 따라서 global minimum이 아니라 local minimum을 찾을 수 있음\n",
        "\n",
        "-> 따라서 gradient descent algorithm 사용 불가"
      ]
    }
  ]
}